{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-26T05:56:33.065967Z",
     "start_time": "2025-11-26T05:56:32.716540Z"
    }
   },
   "source": [
    "a={'a':10,'b':20,'c':30}\n",
    "print(type(a[0]))"
   ],
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m a\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m'\u001B[39m\u001B[38;5;124ma\u001B[39m\u001B[38;5;124m'\u001B[39m:\u001B[38;5;241m10\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m'\u001B[39m:\u001B[38;5;241m20\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mc\u001B[39m\u001B[38;5;124m'\u001B[39m:\u001B[38;5;241m30\u001B[39m}\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;28mtype\u001B[39m(\u001B[43ma\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m))\n",
      "\u001B[1;31mKeyError\u001B[0m: 0"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T07:13:00.479986Z",
     "start_time": "2025-11-26T07:12:59.639832Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def Get_feature_all(feature_hidden_1, feature_skip_list_1):\n",
    "    \"\"\"\n",
    "    将 bottleneck 特征和 skip connection 特征全部重排(PixelShuffle逆操作)到统一的空间尺寸并拼接。\n",
    "    \n",
    "    Args:\n",
    "        feature_hidden_1: [B, 512, 8, 8]\n",
    "        feature_skip_list_1: List of tensors, 长度12\n",
    "                             从 Layer 0 (128,64,64) 到 Layer 11 (512,8,8)\n",
    "    \n",
    "    Returns:\n",
    "        feature: [B, Total_Channels, 64, 64]\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. 获取基础维度\n",
    "    B, C_hidden, H_s, W_s = feature_hidden_1.shape \n",
    "    # H_s=8, W_s=8\n",
    "    \n",
    "    # 2. 设定目标尺寸 (根据你的要求: H*8, W*8 -> 64x64)\n",
    "    # 注意：这里的 8 是基于 feature_hidden_1 的尺寸放大的倍数\n",
    "    H_target = H_s * 8 \n",
    "    W_target = W_s * 8\n",
    "    \n",
    "    # 用于收集所有处理后的特征图\n",
    "    processed_features = []\n",
    "\n",
    "    # 3. 处理 Hidden Feature (Bottleneck)\n",
    "    # [B, 512, 8, 8] -> [B, ?, 64, 64]\n",
    "    # 通道计算: 512 * (8*8) / (64*64) = 512 / 64 = 8\n",
    "    C_hidden_new = int(C_hidden * H_s * W_s / (H_target * W_target))\n",
    "    feature_hidden_reshaped = feature_hidden_1.view(B, C_hidden_new, H_target, W_target)\n",
    "    \n",
    "    # 将 Hidden 层先加入列表 (或者你想把它放在最后也可以，这里默认放最前)\n",
    "    processed_features.append(feature_hidden_reshaped)\n",
    "\n",
    "    # 4. 循环处理 Skip List (倒序: Layer 11 -> Layer 0)\n",
    "    # 使用 while 循环配合 pop，直到列表为空\n",
    "    while feature_skip_list_1:\n",
    "        # 弹出最后一个元素 (例如 Layer 11)\n",
    "        current_feat = feature_skip_list_1.pop()\n",
    "        \n",
    "        # 获取当前特征的形状\n",
    "        # e.g., Layer 11: [B, 512, 8, 8]\n",
    "        # e.g., Layer 9:  [B, 384, 8, 8]\n",
    "        # e.g., Layer 0:  [B, 128, 64, 64]\n",
    "        b, c, h, w = current_feat.shape\n",
    "        \n",
    "        # 自动计算重排后的新通道数\n",
    "        # 原理：体积守恒 (C * H * W) = (C_new * H_target * W_target)\n",
    "        c_new = (c * h * w) / (H_target * W_target)\n",
    "        \n",
    "        # 检查是否能整除 (为了安全性)\n",
    "        if c_new % 1 != 0:\n",
    "            raise ValueError(f\"Feature shape ({c},{h},{w}) cannot be reshaped to ({H_target},{W_target})\")\n",
    "        \n",
    "        c_new = int(c_new)\n",
    "        \n",
    "        # 执行 View 操作 (Depth-to-Space)\n",
    "        feat_reshaped = current_feat.view(B, c_new, H_target, W_target)\n",
    "        \n",
    "        # 加入列表\n",
    "        processed_features.append(feat_reshaped)\n",
    "\n",
    "    # 5. 最终拼接\n",
    "    # 列表里的 tensor 现在都是 [B, C_n, 64, 64]，在通道维 dim=1 拼接\n",
    "    feature = torch.cat(processed_features, dim=1)\n",
    "    \n",
    "    return feature\n",
    "\n",
    "# --- 测试代码 ---\n",
    "if __name__ == '__main__':\n",
    "    # 模拟输入数据\n",
    "    B = 2\n",
    "    feature_hidden = torch.randn(B, 512, 8, 8)\n",
    "    \n",
    "    # 模拟 skip_list (对应你给出的 shape)\n",
    "    skip_list = []\n",
    "    # Layer 0-2: [128, 64, 64]\n",
    "    for _ in range(3): skip_list.append(torch.randn(B, 128, 64, 64))\n",
    "    # Layer 3: [128, 32, 32]\n",
    "    skip_list.append(torch.randn(B, 128, 32, 32))\n",
    "    # Layer 4-5: [256, 32, 32]\n",
    "    for _ in range(2): skip_list.append(torch.randn(B, 256, 32, 32))\n",
    "    # Layer 6: [256, 16, 16]\n",
    "    skip_list.append(torch.randn(B, 256, 16, 16))\n",
    "    # Layer 7-8: [384, 16, 16]\n",
    "    for _ in range(2): skip_list.append(torch.randn(B, 384, 16, 16))\n",
    "    # Layer 9: [384, 8, 8]\n",
    "    skip_list.append(torch.randn(B, 384, 8, 8))\n",
    "    # Layer 10-11: [512, 8, 8]\n",
    "    for _ in range(2): skip_list.append(torch.randn(B, 512, 8, 8))\n",
    "    \n",
    "    # 运行函数\n",
    "    out = Get_feature_all(feature_hidden, skip_list)\n",
    "    print(f\"Final Output Shape: {out.shape}\")\n",
    "    # 预期输出通道数计算:\n",
    "    # Hidden(8) + L11(8) + L10(8) + L9(6) + L8(24) + L7(24) + L6(16) + \n",
    "    # L5(64) + L4(64) + L3(32) + L2(128) + L1(128) + L0(128)\n",
    "    # 总和应该是一个整数，例如 646 左右"
   ],
   "id": "b5134f42c3a2b6f3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Output Shape: torch.Size([2, 638, 64, 64])\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-26T07:25:43.488935Z",
     "start_time": "2025-11-26T07:25:43.448858Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "def Split_feature_all(feature_hidden_fusion):\n",
    "    \"\"\"\n",
    "    将融合后的特征图 [B, 638, 64, 64] 拆解还原回 Hidden 和 Skip List。\n",
    "    \n",
    "    Args:\n",
    "        feature_hidden_fusion: [B, 638, 64, 64]\n",
    "    \n",
    "    Returns:\n",
    "        feature_hidden: [B, 512, 8, 8]\n",
    "        feature_skip_list: List, 包含 Layer 0 到 Layer 11 的特征图 (正序)\n",
    "    \"\"\"\n",
    "    \n",
    "    B, Total_C, H, W = feature_hidden_fusion.shape\n",
    "    # H=64, W=64\n",
    "    \n",
    "    # 指针：记录当前切分到了哪个通道，从 0 开始\n",
    "    current_channel_ptr = 0\n",
    "    \n",
    "    # ==========================================\n",
    "    # 1. 还原 Feature Hidden\n",
    "    # ==========================================\n",
    "    # Hidden 原始形状: [512, 8, 8]\n",
    "    # 压缩后通道数: 512 * (8*8) / (64*64) = 8\n",
    "    c_hidden_compressed = 8\n",
    "    \n",
    "    # 切片\n",
    "    hidden_slice = feature_hidden_fusion[:, current_channel_ptr : current_channel_ptr + c_hidden_compressed, :, :]\n",
    "    # 还原形状 [B, 512, 8, 8]\n",
    "    feature_hidden = hidden_slice.view(B, 512, 8, 8)\n",
    "    \n",
    "    # 更新指针\n",
    "    current_channel_ptr += c_hidden_compressed\n",
    "\n",
    "    # ==========================================\n",
    "    # 2. 还原 Skip List\n",
    "    # ==========================================\n",
    "    # 注意：在 Get 阶段，我们是 pop() 出来的，所以拼接顺序是 Layer 11 -> Layer 10 -> ... -> Layer 0\n",
    "    # 所以这里定义的配置表必须也是这个顺序\n",
    "    \n",
    "    # 定义每一层的原始形状 (Channel, H, W)\n",
    "    # 顺序：Layer 11 -> Layer 0\n",
    "    layers_config_reverse = [\n",
    "        (512, 8, 8),   # Layer 11\n",
    "        (512, 8, 8),   # Layer 10\n",
    "        (384, 8, 8),   # Layer 9  (现在可以完美还原，无特殊操作)\n",
    "        (384, 16, 16), # Layer 8\n",
    "        (384, 16, 16), # Layer 7\n",
    "        (256, 16, 16), # Layer 6\n",
    "        (256, 32, 32), # Layer 5\n",
    "        (256, 32, 32), # Layer 4\n",
    "        (128, 32, 32), # Layer 3\n",
    "        (128, 64, 64), # Layer 2\n",
    "        (128, 64, 64), # Layer 1\n",
    "        (128, 64, 64)  # Layer 0\n",
    "    ]\n",
    "    \n",
    "    temp_skip_list = []\n",
    "    \n",
    "    for (org_c, org_h, org_w) in layers_config_reverse:\n",
    "        # 1. 计算这一层在 64x64 画布上占用了多少通道\n",
    "        # 公式: c_new = (C * H * W) / (64 * 64)\n",
    "        c_compressed = int((org_c * org_h * org_w) / (H * W))\n",
    "        \n",
    "        # 2. 切片提取\n",
    "        feat_slice = feature_hidden_fusion[:, current_channel_ptr : current_channel_ptr + c_compressed, :, :]\n",
    "        \n",
    "        # 3. 还原形状 (Space-to-Depth)\n",
    "        feat_restored = feat_slice.view(B, org_c, org_h, org_w)\n",
    "        \n",
    "        # 4. 加入临时列表\n",
    "        temp_skip_list.append(feat_restored)\n",
    "        \n",
    "        # 5. 更新指针\n",
    "        current_channel_ptr += c_compressed\n",
    "\n",
    "    # ==========================================\n",
    "    # 3. 整理返回结果\n",
    "    # ==========================================\n",
    "    # temp_skip_list 目前是 [Layer 11, Layer 10, ..., Layer 0]\n",
    "    # 通常网络层级列表都是正序的 [Layer 0, ..., Layer 11]，所以这里反转一下\n",
    "    feature_skip_list = temp_skip_list[::-1]\n",
    "    \n",
    "    return feature_hidden, feature_skip_list\n",
    "\n",
    "# --- 测试代码 ---\n",
    "if __name__ == '__main__':\n",
    "    # 模拟输入 [B, 638, 64, 64]\n",
    "    B = 2\n",
    "    feature_fusion = torch.randn(B, 638, 64, 64)\n",
    "    \n",
    "    h, skips = Split_feature_all(feature_fusion)\n",
    "    \n",
    "    print(f\"Hidden shape: {h.shape}\") # 应为 [2, 512, 8, 8]\n",
    "    print(f\"Skip list length: {len(skips)}\") # 应为 12\n",
    "    print(f\"Layer 0 shape: {skips[0].shape}\") # 应为 [2, 128, 64, 64]\n",
    "    print(f\"Layer 9 shape: {skips[9].shape}\") # 应为 [2, 384, 8, 8]\n",
    "    print(f\"Layer 11 shape: {skips[11].shape}\") # 应为 [2, 512, 8, 8]"
   ],
   "id": "dacd2a9f4b89c632",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden shape: torch.Size([2, 512, 8, 8])\n",
      "Skip list length: 12\n",
      "Layer 0 shape: torch.Size([2, 128, 64, 64])\n",
      "Layer 9 shape: torch.Size([2, 384, 8, 8])\n",
      "Layer 11 shape: torch.Size([2, 512, 8, 8])\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T02:50:28.220846Z",
     "start_time": "2025-11-27T02:50:28.208951Z"
    }
   },
   "cell_type": "code",
   "source": "print('hello world')",
   "id": "ac8bca58eed125b8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T02:51:25.977004Z",
     "start_time": "2025-11-27T02:51:25.937909Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import yaml\n",
    "\n",
    "data = {\"batch_size\": 8, \"lr\": 0.0001, \"use_ddp\": True,\n",
    "        'name':{\n",
    "            'first':'zhangsan',\n",
    "            'second':'lisi'\n",
    "        }}\n",
    "\n",
    "with open(\"config.yaml\", \"w\") as f:\n",
    "    yaml.dump(data, f)"
   ],
   "id": "ea43a67b6df9675b",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T02:45:22.079785Z",
     "start_time": "2025-11-28T02:45:21.214358Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from models.modules.UNet_arch import UNet\n",
    "import torch \n",
    "model=UNet(in_ch=3,out_ch=3,ch=8,ch_mult=[4,8,8,16],embed_dim=8)\n",
    "x=torch.rand(1,3,512,512)\n",
    "pretrained_path='pretrained/AutoEncoder.pth'\n",
    "state_dict=torch.load(pretrained_path)\n",
    "model.load_state_dict(state_dict,strict=True)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    h,hs=model.encode(x)\n",
    "    print(f'h.shape: {h.shape}')\n",
    "    print(f'h.range: {h.min().item()} ~ {h.max().item()}')\n",
    "    for i,hi in enumerate(hs):\n",
    "        print(f'hs[{i}].shape: {hi.shape}')\n",
    "        print(f'hs[{i}].range: {hi.min().item()} ~ {hi.max().item()}')\n",
    "        \n",
    "    \n",
    "    out=model(x)\n",
    "    print(f'out.shape: {out.shape}')\n",
    "    print(f'out.range: {out.min().item()} ~ {out.max().item()}')\n",
    "    \n"
   ],
   "id": "5c993e177ef2e2c8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h.shape: torch.Size([1, 8, 64, 64])\n",
      "h.range: -0.13313032686710358 ~ 0.8203734755516052\n",
      "hs[0].shape: torch.Size([1, 8, 512, 512])\n",
      "hs[0].range: -0.8120931386947632 ~ 1.6001704931259155\n",
      "hs[1].shape: torch.Size([1, 8, 512, 512])\n",
      "hs[1].range: -0.7877449989318848 ~ 1.5025765895843506\n",
      "hs[2].shape: torch.Size([1, 8, 512, 512])\n",
      "hs[2].range: -0.8144247531890869 ~ 1.4652830362319946\n",
      "hs[3].shape: torch.Size([1, 32, 256, 256])\n",
      "hs[3].range: -0.9149216413497925 ~ 1.4275686740875244\n",
      "hs[4].shape: torch.Size([1, 32, 256, 256])\n",
      "hs[4].range: -1.0509828329086304 ~ 1.6208029985427856\n",
      "hs[5].shape: torch.Size([1, 64, 128, 128])\n",
      "hs[5].range: -1.751322865486145 ~ 1.5689940452575684\n",
      "hs[6].shape: torch.Size([1, 64, 128, 128])\n",
      "hs[6].range: -1.8444328308105469 ~ 1.565863847732544\n",
      "hs[7].shape: torch.Size([1, 64, 64, 64])\n",
      "hs[7].range: -2.1619269847869873 ~ 2.4993879795074463\n",
      "hs[8].shape: torch.Size([1, 64, 64, 64])\n",
      "hs[8].range: -1.8443394899368286 ~ 1.8846741914749146\n",
      "out.shape: torch.Size([1, 3, 512, 512])\n",
      "out.range: -0.13677750527858734 ~ 1.0617321729660034\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "# 这里的这样的设计肯定是存在一定的问题的； 一定是存在问题的； "
   ],
   "id": "9a517759c8134303"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
